{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdp import *\n",
    "from utils import print_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(3, 3)\n",
      "(3, 2)\n",
      "(3, 1)\n",
      "Reached charging station: (3, 0)\n",
      ">   >      v   v\n",
      "v   None   v   v\n",
      ">   >      >   v\n",
      "^   .      >   .\n"
     ]
    }
   ],
   "source": [
    "sequential_decision_environment = GridMDP([\n",
    "    [-0.1, -0.1, -0.1, -0.1],\n",
    "    [-0.1, None, -0.1, -0.1],\n",
    "    [-0.1, -0.1, -0.1, -0.1],\n",
    "    [-0.1, -1, -0.1, 10],\n",
    "], terminals=[(3, 0), (1, 0)], init=(3, 3))\n",
    "\n",
    "\n",
    "pi = best_policy(sequential_decision_environment, value_iteration(sequential_decision_environment))\n",
    "mdp = MDPAgent(mdp=sequential_decision_environment, best_policy=pi, start_state=sequential_decision_environment.init)\n",
    "mdp.run()\n",
    "print_table(sequential_decision_environment.to_arrows(pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(3, 2)\n",
      "(2, 2)\n",
      "(2, 1)\n",
      "(2, 2)\n",
      "(2, 2)\n",
      "(3, 2)\n",
      "(2, 2)\n",
      "(2, 1)\n",
      "(3, 1)\n",
      "Reached charging station: (3, 0)\n",
      ">   >      v   v\n",
      "v   None   v   <\n",
      ">   >      >   v\n",
      "^   .      >   .\n"
     ]
    }
   ],
   "source": [
    "sequential_decision_environment1 = GridMDP([\n",
    "    [-0.4, -0.4, -0.4, -0.4],\n",
    "    [-0.4, None, 1, -0.4],\n",
    "    [-0.4, -0.4, 1, -0.4],\n",
    "    [-0.4, -1, -0.4, 10], \n",
    "], terminals=[(3, 0), (1, 0)], init=(3, 3))\n",
    "\n",
    "pi = best_policy(sequential_decision_environment1, value_iteration(sequential_decision_environment1))\n",
    "mdp = MDPAgent(mdp=sequential_decision_environment1, best_policy=pi, start_state=sequential_decision_environment1.init)\n",
    "mdp.run()\n",
    "print_table(sequential_decision_environment1.to_arrows(pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(2, 3)\n",
      "(1, 3)\n",
      "(1, 3)\n",
      "(1, 3)\n",
      "(1, 3)\n",
      "(1, 3)\n",
      "(2, 3)\n",
      "(2, 2)\n",
      "(2, 1)\n",
      "(2, 0)\n",
      "(2, 1)\n",
      "(2, 0)\n",
      "(2, 1)\n",
      "(2, 0)\n",
      "Reached charging station: (3, 0)\n",
      "v   ^      <   <\n",
      "v   None   v   <\n",
      ">   ^      v   <\n",
      "<   .      >   .\n"
     ]
    }
   ],
   "source": [
    "sequential_decision_environment2 = GridMDP([\n",
    "    [0.1, 1, -0.4, -1],\n",
    "    [0.8, None, -0.4, -1],\n",
    "    [0.1, 1.2, 1, -1],\n",
    "    [0.8, -1, 2, 10], \n",
    "], terminals=[(3, 0), (1, 0)], init=(3, 3))\n",
    "\n",
    "pi = best_policy(sequential_decision_environment2, value_iteration(sequential_decision_environment2))\n",
    "mdp = MDPAgent(mdp=sequential_decision_environment2, best_policy=pi, start_state=sequential_decision_environment2.init)\n",
    "mdp.run()\n",
    "print_table(sequential_decision_environment2.to_arrows(pi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs440",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
